<!DOCTYPE html>
<html lang="en">
<head>
  <title>Linked Data Publishing</title>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1">
  <link rel="stylesheet" href="../_shared/styles/shower-ruben.css">
  <link rel="stylesheet" href="../_shared/styles/web-fundamentals.css">
</head>
<body class="shower list">
  <header class="caption">
    <h1>
      <a class="series" href="../">Web Fundamentals</a><br>
      <a class="module" href="#title">Linked Data Publishing</a>
    </h1>
    <p>
      <a href="https://ruben.verborgh.org/">Ruben Verborgh</a>,
      <a href="http://www.ugent.be/">Ghent University</a> – <a href="http://www.imec.be/">imec</a>
    </p>
    <ul class="links">
      <li class="prev">Previous topic: <a href="../semantic-web/">The Semantic Web &amp; Linked Data</a></li>
      <li class="next">Next topic: <a href="../decentralization/">Re-decentralizing the Web</a></li>
    </ul>
  </header>

  <nav>
    <h2><a href="../">Web Fundamentals</a></h2>
    <ol>
      <li><a href="../birds-eye-view/">A Bird’s-Eye View of the Web</a></li>
      <li><a href="../architecture/">Web Architecture &amp; Technologies</a></li>
      <li><a href="../web-apis/">Web APIs</a></li>
      <li><a href="../semantic-web/">The Semantic Web &amp; Linked Data</a></li>
      <li><a href="../linked-data-publishing/">Linked Data Publishing</a></li>
      <li><a href="../decentralization/">Re-decentralizing the Web</a></li>
    </ol>
  </nav>

  <div class="title slide" id="title">
    <h2>
      <a class="series" href="../">Web Fundamentals</a><br>
      <a class="module" href="#title">Linked Data Publishing</a>
    </h2>
    <p class="tweets"><a href="https://twitter.com/search?f=tweets&amp;q=%23WebDev2020">#WebDev2020</a></p>
    <p class="author"><a href="https://ruben.verborgh.org/">Ruben Verborgh</a></p>
    <p class="affiliation">
      <a href="http://www.ugent.be/"><img  class="ugent"  src="../_shared/images/logos/ugent.svg"  alt="Ghent University"></a>
      <a href="http://www.imec.be/"><img class="imec" src="../_shared/images/logos/imec.svg" alt="imec"></a>
      <a href="http://idlab.ugent.be/"><img class="idlab" src="../_shared/images/logos/idlab.svg" alt="IDLab"></a>
    </p>
    <p class="license">
      <a rel="license" href="https://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" src="../_shared/images/cc-by.svg" /></a>
      Except where otherwise noted, the content of these slides is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
    </p>
  </div>

  <div class="dark slide" id="stork">
    <h2>
      Where does Linked Data come from,<br>
      and where does it go?
    </h2>
    <figure class="cover width">
      <img src="images/stork.jpg" alt="[photo of a stork getting Linked Data]">
      <figcaption>
        ©2010 <a href="https://www.flickr.com/photos/mariannedewit/4583392579">Marianne de Wit</a><br>
        ©2014 <a href="http://lod-cloud.net/">M. Schmachtenberg, C. Bizer, A. Jentzsch and R. Cyganiak</a>
      </figcaption>
    </figure>
  </div>

  <div class="slide" id="origins">
    <h2>
      Where does Linked Data come from,<br>
      and where does it go?
    </h2>
    <ul>
      <li class="next">
        Many applications capture data directly<br>
        in the format they will use afterwards.
      </li>
      <li class="next">
        In contrast, most Linked Data<br>
        is not linked at the start.
      </li>
      <li class="next">
        Most Linked Data is actually<br>
        first captured in a different way.
      </li>
    </ul>
  </div>

  <div class="toc slide" id="index">
    <h2>
      <a class="series" href="../">Web Fundamentals</a><br>
      <a class="module" href="#title">Linked Data Publishing</a>
    </h2>
    <ul>
      <li><a href="#life-cycle">Linked Data Life Cycle</a></li>
      <li><a href="#challenges">Semantic Web Challenges</a></li>
      <li><a href="#linked-data-fragments">Linked Data Fragments</a></li>
    </ul>
    <p class="tweets"><a href="https://twitter.com/search?f=tweets&amp;q=%23WebDev2020">#WebDev2020</a></p>
  </div>

  <div class="toc slide" id="life-cycle">
    <h2>
      <a class="series" href="../">Web Fundamentals</a><br>
      <a class="module" href="#title">Linked Data Publishing</a>
    </h2>
    <ul>
      <li class="current">
        <a href="#life-cycle">Linked Data Life Cycle</a>
      </li>
      <li><a href="#challenges">Semantic Web Challenges</a></li>
      <li><a href="#linked-data-fragments">Linked Data Fragments</a></li>
    </ul>
    <p class="tweets"><a href="https://twitter.com/search?f=tweets&amp;q=%23WebDev2020">#WebDev2020</a></p>
  </div>

  <div class="slide" id="life-cycle-diagram">
    <h2>
      Many Linked Data life cycles are proposed.<br>
      This simple cycle consists of 5 steps.
    </h2>
    <iframe class="image" src="images/linked-data-cycle.svg"></iframe>
  </div>

  <div class="slide" id="generate">
    <h2>
      Generation is the step in which<br>
      we convert non-RDF data to RDF.
    </h2>
    <iframe class="image" src="images/linked-data-cycle.svg#generate"></iframe>
  </div>

  <div class="slide" id="web-templating">
    <h2>
      Most representations on the Web<br>
      are generated by templates.
    </h2>
    <ul>
      <li class="next">
        Data resides in a back-end database.
      </li>
      <li class="next">
        The front-end Web application translates
        database entries via templates into representations.
        <ul>
          <li>HTML</li>
          <li>JSON</li>
          <li>…</li>
        </ul>
      </li>
      <li class="next">
        The data model from the database<br>
        easily maps to the target representation.
      </li>
    </ul>
  </div>

  <div class="slide" id="templating-insufficient">
    <h2>
      Templating is not always sufficient<br>
      to create <a href="http://5stardata.info/">5-star Linked Data</a>.
    </h2>
    <ul>
      <li class="next">
        You can upgrade a JSON document to JSON-LD<br>
        by providing a <a href="../semantic-web/#jsonld">relevant JSON-LD context</a>.
        <ul>
          <li>
            A context identifies properties and structural elements,<br>
            but does not create links between resources.
          </li>
        </ul>
      </li>
      <li class="next">
        Remodelling data to RDF on the fly is tricky.
      </li>
      <li class="next">
        Linked Data transcends your application.
        <ul>
          <li>Link to external concepts.</li>
          <li>Reuse external identifiers.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="mapping">
    <h2>
      Linked Data can be generated in batch<br>
      through a <em>mapping</em> process.<br>
    </h2>
    <ul>
      <li class="next">
        A <em>mapping processor</em> takes input sources<br>
        and a mapping file as input.
      </li>
      <li class="next">
        The <em>mapping file</em> explains how input data<br>
        should be converted to the RDF model.
        <ul>
          <li>selectors to locate data</li>
          <li>rules to transform data</li>
        </ul>
      </li>
      <li class="next">
        Different processors have different features.
        <ul class="inline">
          <li>source type support</li>
          <li>interlinking together with mapping</li>
          <li>…</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="ad-hoc-mapping">
    <h2>
      Mapping can be performed with<br>
      ad-hoc scripts for a specific dataset.
    </h2>
    <ul>
      <li>
        You write custom code to handle your case.
      </li>
      <li class="next">
        The short-term costs might be low,<br>
        but long-term maintenance can prove difficult.
        <ul>
          <li>Changes require a developer.</li>
          <li>The mapping is not reusable across datasets.</li>
        </ul>
      </li>
      <li class="next">
        Different but related data sources result in<br>
        duplicated effort and incompatibilities.
      </li>
    </ul>
  </div>

  <div class="slide" id="r2rml">
    <h2>
      <a href="https://www.w3.org/TR/r2rml/">R2RML</a> is an RDF vocabulary to describe<br>
      a mapping of relational data into RDF.
    </h2>
    <ul>
      <li class="next">
        A <a href="https://www.w3.org/TR/r2rml/#triples-map">triples map</a> has access to tables (and queries)<br>
        through <a href="https://www.w3.org/TR/r2rml/#logical-tables">logical tables</a>.
      </li>
      <li class="next">
        These logical tables are mapped with <a href="https://www.w3.org/TR/r2rml/#term-map">term maps</a>.
        <ul>
          <li><a href="https://www.w3.org/TR/r2rml/#subject-map">Subject maps</a> generate resource identifiers.</li>
          <li><a href="https://www.w3.org/TR/r2rml/#predicate-object-map">Predicate-object maps</a> generate the rest of the triple.</li>
        </ul>
      </li>
      <li class="next">
        <a href="https://www.w3.org/TR/r2rml/#term-map">Term maps</a> generate individual RDF terms.
        <ul class="inline">
          <li><a href="https://www.w3.org/TR/r2rml/#constant">constant</a></li>
          <li><a href="https://www.w3.org/TR/r2rml/#from-column">column value</a></li>
          <li><a href="https://www.w3.org/TR/r2rml/#from-template">string template</a></li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="rml">
    <h2>
      <a href="http://rml.io/spec.html">RML</a> is a generalization of <a href="#r2rml">R2RML</a><br>
      toward heterogeneous data sources.
    </h2>
    <ul>
      <li class="next">
        RML abstracts different types of <a href="http://rml.io/spec.html#logical-source">logical sources</a>.
        <ul>
          <li class="next">A source is modelled as an <em>iterator</em> of items.</li>
          <li class="next">
            Sources can be
            <ul class="inline">
              <li>databases</li>
              <li>CSV</li>
              <li>XML</li>
              <li>JSON</li>
              <li>…</li>
            </ul>
          </li>
          <li class="next">The mechanism is extensible through new vocabularies.</li>
        </ul>
      </li>
      <li class="next">
        RML <a href="http://rml.io/spec.html#term-map">term maps</a> use logical sources to create terms.
        <ul>
          <li>
            The contents of iterator items are accessible<br>
            through data-source-specific <a href="http://rml.io/spec.html#referenceFormulation">reference formulations</a>.
          </li>
        </ul>
      </li>
      <li class="next">
        RML can map and interlink heterogeneous sources.
      </li>
    </ul>
  </div>

  <div class="slide" id="performances-example">
    <h2>
      Let us consider an example<br>
      of musical performances.
    </h2>
    <p>
      A JSON file contains a list of performances:
    </p>
<pre><code>{ ... "Performance" :
  { "Perf_ID": "567",
    "Venue": { "Name": "Vooruit",
               "Venue_ID": "78" },
    "Location": { "longitude": "3.725379",
								  "latitude": "51.0477644" } },
    ...
}</code></pre>
  </div>

  <div class="slide" id="performances-mapping">
    <h2>
      The venues could be mapped<br>
      using the following RML document.
    </h2>
<pre><code>&lt;#VenuesMapping&gt;
    rml:logicalSource [
        rml:source "http://ex.com/performances.json";
        rml:referenceFormulation ql:JSONPath;
        rml:iterator "$.Performance.[*]"
    ];
    rr:subjectMap [
        rr:template "http://ex.com/venues/{Venue_ID}"
    ].</code></pre>
  </div>

  <div class="slide" id="performances-mapping-predicate-objects">
    <h2>
      The venues could be mapped<br>
      using the following RML document.
    </h2>
<pre><code>&lt;#VenuesMapping&gt;
    rr:predicateObjectMap [
        rr:predicate geo:long;
        rr:objectMap [ rml:reference "longitude";
                       rr:datatype xsd:float ]
    ], [
        rr:predicate geo:lat;
        rr:objectMap [ rml:reference "latitude";
                       rr:datatype xsd:float ]
    ].</code></pre>
  </div>

  <div class="slide" id="performances-mapping-result">
    <h2>
      The execution of the mapping<br>
      results in an RDF dataset.
    </h2>
<pre><code>...
&lt;http://ex.com/venues/78&gt;
    geo:long 3.725379;
    geo:lat 51.0477644.

&lt;http://ex.com/venues/91&gt;
    geo:long 3.728515;
    geo:lat 51.056008.
...</code></pre>
  </div>

  <div class="slide" id="mapping-extensibility">
    <h2>
      The mapping can be extended<br>
      to include other resources and properties.
    </h2>
    <ul>
      <li class="next">
        RML mappings can incorporate data<br>
        from other sources, even in different formats.
        <ul>
          <li>
            Parts of mapping definitions can be reused.
          </li>
        </ul>
      </li>
      <li class="next">
        RML mappings can look up data from Web APIs.
      </li>
      <li class="next">
        Interlinking can happen at mapping time,<br>
        rather than as a separate step after mapping.
        <ul>
          <li>Reuse identifiers as much as possible.</li>
          <li>Link data as early as possible.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="validate">
    <h2>
      After Linked Data has been generated,<br>
      we can validate it using semantics.
    </h2>
    <iframe class="image" src="images/linked-data-cycle.svg#validate"></iframe>
  </div>

  <div class="slide" id="semantic-validation">
    <h2>
      Validation can be applied<br>
      on different data levels.
    </h2>
    <ul>
      <li class="next">
        validation on the <em>individual field</em> level
        <ul class="inline">
          <li>spelling mistakes</li>
          <li>field overloading</li>
          <li>simple datatypes</li>
          <li>…</li>
        </ul>
      </li>
      <li class="next">
        validation on the <em>structural</em> level
        <ul class="inline">
          <li>integrity</li>
          <li>required and prohibited structures</li>
          <li>…</li>
        </ul>
      </li>
      <li class="next">
        validation on the <em>semantic</em> level
        <ul class="inline">
          <li>domain and range of values</li>
          <li>inconsistencies</li>
          <li>…</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="database-validation">
    <h2>
      Databases only allow for<br>
      rudimentary constraint validation.
    </h2>
    <ul>
      <li>
        They perform elementary value-type checks.
        <ul>
          <li>field <code>Temperature</code> has type <code>INTEGER</code></li>
        </ul>
      </li>
      <li>
        They can ensure referential integrity.
        <ul>
          <li>Does a referenced record exist?</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="schema-validation">
    <h2>
      Schemas can validate conformance to<br>
      a reusable set of structural constraints.
    </h2>
    <ul>
      <li class="next">
        The <a href="https://www.w3.org/TR/shacl/">Shapes Constraint Language (SHACL)</a>
        allows for<br>
        the specification of validation rules in RDF.
        <ul>
          <li>
            Use nested <em>shapes</em> to describe the desired structure.
          </li>
        </ul>
      </li>
      <li class="next">
        <a href="https://shex.io/">Shape Expressions (ShEx)</a>
        serve similar goals,<br>
        but have a higher expressivity.
      </li>
      <li class="next">
        Both languages soften the open-world assumption<br>
        by providing <em>expectations</em> for a specific context.
        <ul>
          <li>
            This is useful for apps with specific assumptions.
          </li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="ontological-validation">
    <h2>
      Ontologies allow for more specific<br>
      content-based validation.
    </h2>
    <ul>
    <li class="next">
        More specific types can be defined,<br>
        and their definitions can be reused.
        <ul class="inline">
          <li>temperature</li>
          <li>days per month</li>
          <li>…</li>
        </ul>
      </li>
      <li class="next">
        Type checking can take more factors into account.
        <ul class="inline">
          <li>domain and range</li>
          <li>incompatible types</li>
          <li>…</li>
        </ul>
      </li>
      <li class="next">
        Additional <a href="../semantic-web/#semantic-web-reasoning">reasoning</a>
        can further identify problems.
      </li>
    </ul>
  </div>

  <div class="tight slide" id="validation-range-domain">
    <h2>
      In the following example, type checking<br>
      identifies an incorrect triple.
    </h2>
    <p>The ontology defines the following constraints:</p>
    <pre><code>foaf:knows rdfs:domain foaf:Person;
           rdfs:range foaf:Person.
:Mathematics a :Course.
:Course owl:disjointWith foaf:Person.</code></pre>
    <p class="next">This triple violates those constraints:</p>
    <pre class="next"><code>:Albert foaf:knows :Mathematics.</code></pre>
  </div>

  <div class="tight slide" id="validation-complex-constraints">
    <h2>
      Violations <em>across</em> triples can be identified,<br>
      but not always automatically resolved.
    </h2>
    <p>The ontology defines the following constraints:</p>
    <pre><code>:isBiologicalFatherOf a owl:IrreflexiveProperty;
                        owl:InverseFunctionalProperty.</code></pre>
    <p class="next">The triples below are inconsistent:</p>
    <pre class="next"><code>:Albert  :isBiologicalFatherOf :Albert.
:Albert  :isBiologicalFatherOf :Delphine.
:Jacques :isBiologicalFatherOf :Delphine.</code></pre>
    <p class="next">Which ones are correct is not known.</p>
  </div>

  <div class="slide" id="automated-validation">
    <h2>
      Automated validation tells you<br>
      whether data makes sense.
    </h2>
    <ul>
      <li class="next">
        <a href="https://github.com/AKSW/RDFUnit">RDFUnit</a> assesses the quality of a dataset<br>
        by running automated tests on it.
      </li>
      <li class="next">
        Ontologies used in a dataset can be looked up<br>
        by <a href="../semantic-web/#http-uris">dereferencing</a> its concepts.
      </li>
      <li class="next">
        The constraints in the ontology are transformed<br>
        into SPARQL queries and then evaluated.
        <ul>
          <li>This results in warnings and/or errors.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="mapping-validations">
    <h2>
      By validating during the <a href="#mapping">mapping process</a>,<br>
      we detect quality issues before they occur.
    </h2>
    <ul>
      <li class="next">
        Batch mapping processes<br>
        can generate millions of triples.
        <ul>
          <li class="next">
            If we find a quality issue only afterwards,<br>
            we have to restart the entire mapping.
          </li>
        </ul>
      </li>
      <li class="next">
        Checking quality during mapping allows<br>
        pinpointing the cause of errors and fixing them.
        <ul>
          <li>Mapping rules that fail need not be not executed first.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="publish">
    <h2>
      As soon as Linked Data is ready,<br>
      it can be published for consumption.
    </h2>
    <iframe class="image" src="images/linked-data-cycle.svg#publish"></iframe>
  </div>

  <div class="slide" id="linked-data-publication">
    <h2>
      There are roughly 3 ways of<br>
      publishing Linked Data on the Web.
    </h2>
    <ul>
      <li>
        <a href="#data-dump">data dump</a>
        <ul>
          <li class="next">provide an archive file with the entire dataset</li>
        </ul>
      </li>
      <li>
        <a href="#sparql-endpoints">SPARQL endpoint</a>
        <ul>
          <li class="next">expose a triple store’s query interface</li>
        </ul>
      </li>
      <li>
        <a href="#linked-data-documents">Linked Data documents</a>
        <ul>
          <li class="next">browse triples per resource / topic</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="data-dump">
    <h2>
      A data dump places all dataset triples<br>
      in one or more archive files.
    </h2>
    <ul>
      <li>
        Dumps need to be downloaded entirely<br>
        before they can be queried.
        <ul>
          <li>Dump files can be several gigabytes.</li>
        </ul>
      </li>
      <li class="next">
        They offer the client full flexibility<br>
        to choose how data is processed.
      </li>
      <li class="next">
        Keeping data up-to date requires effort.
        <ul>
          <li>redownload the entire dump</li>
          <li>download and apply incremental patches</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="data-dump-example">
    <h2>
      A data dump places all dataset triples<br>
      in one or more archive files.
    </h2>
    <iframe class="website" src="http://downloads.dbpedia.org/2016-04/core/"></iframe>
  </div>

  <div class="slide" id="sparql-endpoint">
    <h2>
      A SPARQL endpoint lets clients evaluate<br>
      arbitrary (read-only) queries on a server.
    </h2>
    <ul>
      <li class="next">
        This gives clients direct access to<br>
        (only) the data they are interested in.
        <ul>
          <li>Only very little bandwidth is required.</li>
        </ul>
      </li>
      <li class="next">
        Data is always up-to-date.
      </li>
      <li class="next">
        The per-request cost for SPARQL endpoints<br>
        is much higher than for other HTTP servers.
        <ul>
          <li>Few servers allow arbitrarily complicated queries.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="sparql-endpoint-example">
    <h2>
      A SPARQL endpoint lets clients evaluate<br>
      arbitrary (read-only) queries on a server.
    </h2>
    <iframe class="website" src="http://dbpedia.org/sparql"></iframe>
  </div>

  <div class="slide" id="linked-data-documents">
    <h2>
      Linked Data documents provide<br>
      per-topic access to a dataset.
    </h2>
    <ul>
      <li class="next">
        They follow the <a href="../semantic-web/#linked-data-principles">Linked Data principles</a>.
        <ul>
          <li>The information structure resembles typical webpages.</li>
        </ul>
      </li>
      <li class="next">
        Browsing up-to-date datasets is straightforward.
      </li>
      <li class="next">
        Query evaluation is possible through<br>
        <a href="http://squin.sourceforge.net/index.shtml">link-traversal-based querying</a>.
        <ul>
          <li>
            The evaluation of SPARQL queries is rather slow.
          </li>
          <li>
            Completeness cannot always be guaranteed.
          </li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="linked-data-documents-example">
    <h2>
      Linked Data documents provide<br>
      per-topic access to a dataset.
    </h2>
    <iframe class="website" src="http://dbpedia.org/resource/Tim_Berners-Lee"></iframe>
  </div>

  <div class="slide" id="query">
    <h2>
      Once Linked Data is published on the Web,<br>
      clients can evaluate queries over it.
    </h2>
    <iframe class="image" src="images/linked-data-cycle.svg#query"></iframe>
  </div>

  <div class="slide" id="query-introduction">
    <h2>
      Just like on the “human” Web,<br>
      querying goes beyond browsing.
    </h2>
    <ul>
      <li>Where can we find the data we need?</li>
      <li>How can we access that data?</li>
      <li>How do we combine it with other data?</li>
    </ul>
  </div>

  <div class="slide" id="query-interface">
    <h2>
      The possibilities for query evaluation<br>
      depend on how data is made available.
    </h2>
    <ul>
      <li class="next">
        Is the data available in RDF?
        <ul>
          <li>Then we should discover the ontologies used.</li>
        </ul>
      </li>
      <li class="next">
        Is the data linked to other data?
        <ul>
          <li>Then we can / might need to involve other datasets.</li>
        </ul>
      </li>
      <li class="next">
        In what interfaces is the data available?
        <ul>
          <li>The client might need to evaluate (a part of) the query.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="federation">
    <h2>
      Evaluating queries over a <em>federation</em><br>
      of interfaces introduces new challenges.
    </h2>
    <ul>
      <li class="next">
        Which interface has the necessary data?
        <ul>
          <li>If there are multiple, which one is the best?</li>
        </ul>
      </li>
      <li class="next">
        How will the query evaluation be coordinated?
        <ul>
          <li>Does one SPARQL endpoint talk to others?</li>
          <li>Does the client talk to all SPARQL endpoints?</li>
        </ul>
      </li>
      <li class="next">
        In what order are subqueries executed?
        <ul>
          <li>We should minimize high numbers of intermediary results.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="enhance">
    <h2>
      Enhancements let client feedback<br>
      find its way back to the source.
    </h2>
    <iframe class="image" src="images/linked-data-cycle.svg#enhance"></iframe>
  </div>

  <div class="slide" id="corrections-mistakes">
    <h2>
      Data doesn’t stop when published.<br>
      It only just begins.
    </h2>
    <ul>
      <li class="next">
        When users query data sources,<br>
        they might spot mistakes or missing data.
      </li>
      <li class="next">
        Can users correct data?<br>
        Can they create new data?
      </li>
      <li class="next">
        Especially open data should be open to corrections.
        <ul>
          <li>Feedback is a core added value of <em>open</em>.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="feedback-loops">
    <h2>
      Unfortunately, such feedback loops<br>
      are still rare for Linked Data.
    </h2>
    <p>
      Open challenges include:
    </p>
    <ul>
      <li>How can end users edit triples?</li>
      <li>How can edits be reviewed?</li>
      <li>How do we keep track of history?</li>
    </ul>
  </div>

  <div class="slide" id="provenance">
    <h2>
      <a href="https://www.w3.org/TR/prov-overview/">Provenance</a> allows modeling<br>
      the history trail of facts.
    </h2>
    <ul>
      <li class="next">
        Provenance captures entities, activities, and people<br>
        involved in producing a resource.
      </li>
      <li class="next">
        Provenance can assess quality, reliability, or trust.
        <ul>
          <li>
            Tim Berners-Lee sketched an <a href="https://www.w3.org/DesignIssues/UI.html"><em>Oh yeah?</em> button</a><br>
            you click to gain trust in information on the Web.
          </li>
        </ul>
      </li>
      <li class="next">
        Many provenance challenges are still open.
        <ul>
          <li>How to generate provenance (during mapping)?</li>
          <li>How to store <var>n</var> provenance triples per data triple?</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="reverse-mapping">
    <h2>
      <em>Reverse mappings</em> could feed edits<br>
      back to the original source.
    </h2>
    <ul>
      <li class="next">
        If the RDF triples are generated from raw data,<br>
        edits to the triples should be ported back.
        <ul>
          <li>If not, they are overwritten by the next mapping.</li>
        </ul>
      </li>
      <li class="next">
        If the <a href="#mapping">mapping file</a> declaratively specifies<br>
        how a source maps to triples,<br>
        we might be able to reverse it automatically.
        <ul>
          <li>Another reason to not prefer <a href="#ad-hoc-mapping">custom scripts</a>.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="toc slide" id="challenges">
    <h2>
      <a class="series" href="../">Web Fundamentals</a><br>
      <a class="module" href="#title">Linked Data Publishing</a>
    </h2>
    <ul>
      <li><a href="#life-cycle">Linked Data Life Cycle</a></li>
      <li class="current">
        <a href="#challenges">Semantic Web Challenges</a>
      </li>
      <li><a href="#linked-data-fragments">Linked Data Fragments</a></li>
    </ul>
    <p class="tweets"><a href="https://twitter.com/search?f=tweets&amp;q=%23WebDev2020">#WebDev2020</a></p>
  </div>

  <div class="slide" id="semantic-web-vision">
    <h2>
      The original Semantic Web vision<br>
      features intelligent agents.
    </h2>
    <blockquote>
      <p>
        Schedule bi-weekly appointments<br>
        with a licensed physical therapist,<br>
        specialized in a particular field,<br>
        living nearby home or my workplace.
      </p>
      <cite>adapted from <a href="http://www.scientificamerican.com/article/the-semantic-web/"><em>The Semantic Web</em></a></cite>
    </blockquote>
  </div>

  <div class="slide" id="smartphones">
    <h2>
      Do we still need the Semantic Web<br>
      with a smartphone in our pockets?
    </h2>
    <img src="../birds-eye-view/images/siri.png" alt="[an iPhone running Siri]" style="float: right; height: 430px;">
    <ul>
      <li>
        On the surface, the current generation of smart devices delivers
        much of what the Semantic Web promised.
        <ul>
          <li class="next">Just realize the intelligence<br> is <em>not</em> on your smartphone.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="preprogrammed-agents">
    <h2>
      The current generation of agents<br>
      only performs preprogrammed acts.
    </h2>
    <ul>
      <li>
        The Semantic Web’s goal is to allow this
        with <em>unknown</em> services and data.
        <ul>
          <li class="next">
            The service inclusion process for current digital agents<br>
            is non-transparent and non-democratic, unlike the Web.
          </li>
          <li class="next">
            Even if it were democratic, it wouldn’t scale,<br>
            since the integration is hardcoded.
          </li>
        </ul>
      </li>
      <li class="next">
        Machines should discover services and data<br>
        and use them <em>without</em> any prior knowledge.
        <ul>
          <li><a href="../web-apis/#owl-s">Semantic service descriptions</a> did not really catch on.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="chicken-and-egg">
    <h2>
      Before Linked Data, the Semantic Web<br>
      suffered from a <a href="../birds-eye-view/#chicken-and-egg">chicken-and-egg problem</a>.
    </h2>
    <ul>
      <li class="next">
        Applications and data were waiting for each other.
        <ul>
          <li>Have <em>you</em> used the Semantic Web yet?</li>
        </ul>
      </li>
      <li class="next">
        Now, at least the data is there on a large scale.
        <ul>
          <li class="opinion">But that is not sufficient to <a href="https://lists.w3.org/Archives/Public/semantic-web/2015Nov/0047.html">call the Semantic Web a success</a>.</li>
        </ul>
      </li>
      <li class="next">
        What more do we need to kickstart things?
      </li>
    </ul>
  </div>

  <div class="slide" id="where-are-the-agents">
    <h2>
      We have all the infrastructure,<br>
      so <a href="https://www.computer.org/csdl/mags/ex/2007/03/x3002.pdf">where are all the intelligent agents?</a>
    </h2>
    <ul>
      <li class="next">
        We published billions of triples,<br>spanning many domains.
      </li>
      <li class="next">
        Many answers we seek are out there.
      </li>
      <li class="next">
        But how do we find them?<br>How do we access them?
      </li>
    </ul>
  </div>

  <div class="slide" id="public-sparql-endpoints">
    <h2>
      The SemWeb’s answer to live querying<br>
      has been “public SPARQL endpoints”.
    </h2>
    <ul>
      <li>
        A <a href="../semantic-web/#sparql-protocol">SPARQL endpoint</a> allows clients<br>
        to send any SPARQL query for evaluation.
        <ul>
          <li><code>/sparql?query={query}</code></li>
        </ul>
      </li>
      <li class="next">
        What could possibly go wrong?
        <ul>
          <li class="next">What if clients send expensive queries?</li>
          <li class="next">What if many clients send medium queries?</li>
          <li class="next">How will you mirror the server’s data?</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="sql-versus-sparql">
    <h2>
      Would you put your SQL database<br>
      publicly on the Web—even just read-only?
    </h2>
    <ul>
      <li class="next">
        Normally, Web interfaces purposely<br>
        limit access to the underlying database.
      </li>
      <li class="next">
        RDF removes the <em>model</em> barrier, and thus<br>
        the need for clients to know the data schema.
        <ul>
          <li>The interface is not necessary as an <em>abstraction</em>.</li>
        </ul>
      </li>
      <li class="next">
        Yet RDF does not remove the <em>complexity</em> barrier.
        <ul>
          <li class="opinion">The interface might still be necessary as a <em>limiter</em>.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="public-endpoint-availability">
    <h2>
      Most public SPARQL endpoints<br>
      have <a href="http://www.deri.ie/sites/default/files/publications/paperiswc.pdf">less than 95% availability</a>.
    </h2>
    <ul>
      <li class="next">
        The average SPARQL endpoint<br>
        is down for 1.5 days <em>each month</em>.
        <ul>
          <li class="next">
            Web servers usually express availability in <em>number of nines</em>.
          </li>
        </ul>
      </li>
      <li class="next">
        Building a reliable application on top of<br>
        a publicly queryable Linked Data source<br>
        is thus currently not realistic.
        <ul>
          <li class="next">Things only get worse if you need <em>multiple</em> sources.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="availability-problem">
    <h2>
      Linked Data availability on the Web<br>
      is a serious, two-sided problem.
    </h2>
    <ol>
      <li class="next">
        Public SPARQL endpoints that exist, lack uptime.
        <ul>
          <li>
            High uptime would be possible,<br>
            but comes with a high server cost.
          </li>
        </ul>
      </li>
      <li class="next">
        For most datasets, no public endpoint exists.
        <ul>
          <li>
            Publishers provide <a href="#data-dump">data dumps</a> instead,<br>
            but these cannot be queried live.
          </li>
        </ul>
      </li>
    </ol>
  </div>

  <div class="slide" id="private-endpoints">
    <h2 class="opinion">
      If we all host a private endpoint,<br>
      it is no longer a Semantic <em>Web</em>.
    </h2>
    <blockquote>
      <p class="next">
        If you have operational need<br>
        for SPARQL-accessible data,<br>
        you must have your own infrastructure.
      </p>
      <p class="next">
        No public endpoints.<br>
        Public endpoints are for lookups and discovery;<br>
        sort of a dataset demo.
      </p>
      <cite><a href="http://www.openlinksw.com/weblog/oerling/?id=1815">Orri Erling</a>, OpenLink (2014)</cite>
    </blockquote>
  </div>

  <div class="slide" id="intelligent-servers">
    <h2 class="opinion">
      20 years of Semantic Web research<br>
      has mostly lead to intelligent <em>servers</em>.
    </h2>
    <ul>
      <li class="next">
        Without a cost model behind it,<br>
        server intelligence is not scalable.
        <ul>
          <li>Not every Web resource can be created just for you.</li>
        </ul>
      </li>
      <li class="next opinion">
        Instead of trying to be intelligent ourselves,<br>
        we should <em>enable</em> clients to be intelligent.
        <ul>
          <li class="next">
            What is a good basic set of conditions to guarantee<br>
            <em>realistic</em> availability of Linked Data on the Web?
          </li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="toc slide" id="linked-data-fragments">
    <h2>
      <a class="series" href="../">Web Fundamentals</a><br>
      <a class="module" href="#title">Linked Data Publishing</a>
    </h2>
    <ul>
      <li><a href="#life-cycle">Linked Data Life Cycle</a></li>
      <li><a href="#challenges">Semantic Web Challenges</a></li>
      <li class="current">
        <a href="#linked-data-fragments">Linked Data Fragments</a>
        <ul>
          <li class="current"><a href="#linked-data-fragments">Trade-offs for the Semantic Web</a></li>
          <li><a href="#querying-tpfs">Querying Triple Pattern Fragments</a></li>
          <li><a href="#evaluating-trade-offs">Evaluating the Trade-offs</a></li>
        </ul>
      </li>
    </ul>
    <p class="tweets"><a href="https://twitter.com/search?f=tweets&amp;q=%23WebDev2020">#WebDev2020</a></p>
  </div>

  <div class="slide" id="linked-data-spectrum">
    <h2>
      Possible Linked Data interfaces exist<br>
      in between the two extremes.
    </h2>
    <iframe class="image" src="images/ldf-axis.svg"></iframe>
  </div>

  <div class="slide" id="linked-data-fragments-definition">
    <h2>
      <em>Linked Data Fragments</em> is a uniform view<br>
      on Linked Data interfaces.
    </h2>
    <iframe class="image" src="images/ldf-axis.svg"></iframe>
    <p class="next label" style="top:207px;left:240px">
      Every Linked Data interface<br>
      offers <em>specific fragments</em><br>
      of a Linked Data set.
    </p>
  </div>

  <div class="slide" id="ldf-characteristics">
    <h2>
      Each type of Linked Data Fragment<br>
      is defined by three characteristics.
    </h2>
    <h3>Linked Data Fragment</h3>
    <dl>
      <dt>data</dt>
      <dd class="next"><em>What triples does the fragment contain?</em></dd>
      <dt>metadata</dt>
      <dd class="next"><em>Do we know more about the data/fragment?</em></dd>
      <dt>controls</dt>
      <dd class="next"><em>How can we access more data?</em></dd>
    </dl>
  </div>

  <div class="slide" id="data-dump-characteristics">
    <h2>
      Each type of Linked Data Fragment<br>
      is defined by three characteristics.
    </h2>
    <h3>data dump</h3>
    <dl>
      <dt>data</dt>
      <dd>all dataset triples</dd>
      <dt>metadata</dt>
      <dd>number of triples, file size</dd>
      <dt>controls</dt>
      <dd><em>(none)</em></dd>
    </dl>
  </div>

  <div class="slide" id="sparql-result-characteristics">
    <h2>
      Each type of Linked Data Fragment<br>
      is defined by three characteristics.
    </h2>
    <h3>SPARQL query result</h3>
    <dl>
      <dt>data</dt>
      <dd>triples matching the query</dd>
      <dt>metadata</dt>
      <dd><em>(none)</em></dd>
      <dt>controls</dt>
      <dd><em>(none)</em></dd>
    </dl>
  </div>

  <div class="slide" id="ld-document-characteristics">
    <h2>
      Each type of Linked Data Fragment<br>
      is defined by three characteristics.
    </h2>
    <h3>Linked Data document</h3>
    <dl>
      <dt>data</dt>
      <dd>triples about a topic</dd>
      <dt>metadata</dt>
      <dd>creator, maintainer, …</dd>
      <dt>controls</dt>
      <dd>links to other Linked Data documents</dd>
    </dl>
  </div>

  <div class="slide" id="new-tradeoff-mix">
    <h2>
      We designed a new trade-off mix<br>
      with low cost and high availability.
    </h2>
    <iframe class="image" src="images/ldf-axis.svg"></iframe>
  </div>

  <div class="slide" id="triple-pattern-fragments">
    <h2>
      A Triple Pattern Fragments interface<br>
      is low-cost and <em>enables</em> clients to query.
    </h2>
    <iframe class="image" src="images/tpf-axis.svg"></iframe>
  </div>

  <div class="slide" id="tpf-characteristics">
    <h2>
      A Triple Pattern Fragment is designed<br>
      to have a good information/cost balance.
    </h2>
    <h3>Triple Pattern Fragment</h3>
    <dl>
      <dt>data</dt>
      <dd class="next">matches of a triple pattern <em>(paged)</em></dd>
      <dt>metadata</dt>
      <dd class="next">total number of matches</dd>
      <dt>controls</dt>
      <dd class="next">access to all other Triple Pattern Fragments<br> of the same dataset</dd>
    </dl>
  </div>

  <div class="slide" id="tpf-example">
    <h2>
      This Triple Pattern Fragment shows<br>
      <a href="http://fragments.dbpedia.org/2016-04/en?subject=&amp;predicate=http%3A%2F%2Fdbpedia.org%2Fontology%2FbirthPlace&amp;object=http%3A%2F%2Fdbpedia.org%2Fresource%2FLondon">subjects born in London</a> from <a href="http://wiki.dbpedia.org/">DBpedia</a>.
    </h2>
    <iframe class="website" src="http://fragments.dbpedia.org/2016-04/en?subject=&amp;predicate=http%3A%2F%2Fdbpedia.org%2Fontology%2FbirthPlace&amp;object=http%3A%2F%2Fdbpedia.org%2Fresource%2FLondon"></iframe>
  </div>

  <div class="slide" id="hdt">
    <h2>
      Triple Pattern Fragments are lightweight,<br>
      because they do not <em>require</em> a triple store.
    </h2>
    <ul>
      <li>
        The interface can be realized with many back-ends.<br>
        <ul>
          <li>A SPARQL endpoint <em>could</em> serve as back-end.</li>
        </ul>
      </li>
      <li class="next">
        Since queries are relatively simple,<br>
        a less expensive data infrastructure is sufficient.
      </li>
      <li class="next">
        The <a href="http://www.rdfhdt.org/">Header–Dictionary–Triples (HDT)</a> format<br>
        stores triples in a compressed file.
        <ul>
          <li>Especially triple-pattern lookups (and counts) are fast.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="final-answer">
    <h2>
      Triple patterns are not the final answer.<br>
      No interface ever will be.
    </h2>
    <ul>
      <li class="next">
        There’s no <em>silver bullet</em>.<br>
        Publication and querying <em>always</em> involves trade-offs.
      </li>
      <li class="next">
        Triple Pattern Fragments aim to test how far<br>
        we can get with <strong>simple servers</strong> and <strong>smart clients</strong>.
      </li>
      <li class="next">
        To verify this, we need to execute the same queries<br>
        on different systems and measure the impact.
      </li>
    </ul>
  </div>

  <div class="toc slide" id="querying-tpfs">
    <h2>
      <a class="series" href="../">Web Fundamentals</a><br>
      <a class="module" href="#title">Linked Data Publishing</a>
    </h2>
    <ul>
      <li><a href="#life-cycle">Linked Data Life Cycle</a></li>
      <li><a href="#challenges">Semantic Web Challenges</a></li>
      <li class="current">
        <a href="#linked-data-fragments">Linked Data Fragments</a>
        <ul>
          <li><a href="#linked-data-fragments">Trade-offs for the Semantic Web</a></li>
          <li class="current"><a href="#querying-tpfs">Querying Triple Pattern Fragments</a></li>
          <li><a href="#evaluating-trade-offs">Evaluating the Trade-offs</a></li>
        </ul>
      </li>
    </ul>
    <p class="tweets"><a href="https://twitter.com/search?f=tweets&amp;q=%23WebDev2020">#WebDev2020</a></p>
  </div>

  <div class="slide" id="tpf-html-form">
    <h2>
      Triple Pattern Fragment servers<br>
      <em>enable</em> clients to be intelligent.
    </h2>
    <dl>
      <dt>controls</dt>
      <dd>
        The HTML representation explains:<br>
        <em>you can query by triple pattern</em>.
      </dd>
    </dl>
    <iframe class="website" src="http://fragments.dbpedia.org/2016-04/en?subject=&amp;predicate=http%3A%2F%2Fdbpedia.org%2Fontology%2FbirthPlace&amp;object=http%3A%2F%2Fdbpedia.org%2Fresource%2FLondon"></iframe>
  </div>

  <div class="slide" id="tpf-rdf-form">
    <h2>
      Triple Pattern Fragment servers<br>
      <em>enable</em> clients to be intelligent.
    </h2>
    <dl>
      <dt>controls</dt>
      <dd>
        The RDF representation explains:<br>
        <em>you can query by triple pattern</em>.
      </dd>
    </dl>
    <pre class="scroll"><code>&lt;http://fragments.dbpedia.org/2016-04/en#dataset&gt; hydra:search [
  hydra:template "http://fragments.dbpedia.org/2016-04/en{?s,p,o}";
  hydra:mapping
    [ hydra:variable "s"; hydra:property rdf:subject ],
    [ hydra:variable "p"; hydra:property rdf:predicate ],
    [ hydra:variable "o"; hydra:property rdf:object ]
].</code></pre>
  </div>

  <div class="slide" id="tpf-html-metadata">
    <h2>
      Triple Pattern Fragment servers<br>
      <em>enable</em> clients to be intelligent.
    </h2>
    <dl>
      <dt>metadata</dt>
      <dd>
        The HTML representation explains:<br>
        <em>this is the number of matches</em>.
      </dd>
    </dl>
    <iframe class="website" src="http://fragments.dbpedia.org/2016-04/en?subject=&amp;predicate=http%3A%2F%2Fdbpedia.org%2Fontology%2FbirthPlace&amp;object=http%3A%2F%2Fdbpedia.org%2Fresource%2FLondon"></iframe>
  </div>

  <div class="slide" id="tpf-rdf-metadata">
    <h2>
      Triple Pattern Fragment servers<br>
      <em>enable</em> clients to be intelligent.
    </h2>
    <dl>
      <dt>metadata</dt>
      <dd>
        The RDF representation explains:<br>
        <em>this is the number of matches</em>.
      </dd>
    </dl>
    <pre><code>&lt;#fragment&gt; void:triples 7937.</code></pre>
  </div>

  <div class="slide" id="tpf-query-evaluation-steps">
    <h2>
      How can a client evaluate<br>
      a SPARQL query over a TPF interface?
    </h2>
    <ul>
      <li class="next">
        Give the client a SPARQL query,<br>
        and the URL of any TPF of the dataset.
      </li>
      <li class="next">
        It uses the <em>controls</em> inside of the fragment<br>
        to determine how to access the dataset.
      </li>
      <li class="next">
        It reads the <em>metadata</em> to decide<br>
        how to plan the query.
      </li>
    </ul>
  </div>

  <div class="slide" id="tpf-execution-example">
    <h2>
      Let’s follow the execution<br>
      of an example SPARQL query.
    </h2>
    <p><em>Find artists born in cities named Waterloo.</em></p>
    <pre><code>SELECT ?person ?city WHERE {
    ?person rdf:type dbpedia-owl:Artist.
    ?person dbpedia-owl:birthPlace ?city.
    ?city foaf:name "Waterloo"@en.
}</code></pre>
    <p>Fragment: <a href="http://fragments.dbpedia.org/2016-04/en">http://fragments.dbpedia.org/2016-04/en</a></p>
  </div>

  <div class="slide" id="tpf-inspect-fragment">
    <h2>
      The client looks inside of the fragment<br>
      to see how it can access the dataset.
    </h2>
    <pre class="scroll"><code>&lt;http://fragments.dbpedia.org/2016-04/en#dataset&gt; hydra:search [
  hydra:template "http://fragments.dbpedia.org/2016-04/en{?s,p,o}";
  hydra:mapping
    [ hydra:variable "s"; hydra:property rdf:subject ],
    [ hydra:variable "p"; hydra:property rdf:predicate ],
    [ hydra:variable "o"; hydra:property rdf:object ]
].</code></pre>
    <p><em>You can query the dataset by triple pattern.</em></p>
  </div>

  <div class="slide" id="tpf-split-query">
    <h2>
      The client splits the query<br>
      into the available fragments.
    </h2>
    <ol class="query">
      <li>
        <code>?person rdf:type dbo:Artist.</code>
      </li>
      <li>
        <code>?person dbo:birthPlace ?city.</code>
      </li>
      <li>
        <code>?city foaf:name "Waterloo"@en.</code>
      </li>
    </ol>
  </div>

  <div class="slide" id="tpf-get-fragments">
    <h2>
      It gets the first page of all fragments<br>
      <span class="next">and inspects their metadata.</span>
    </h2>
    <ol class="query">
      <li>
        <code>?person rdf:type dbo:Artist.</code>
        <span class="next count">96,000</span>
        <ul>
          <li><em>(first 100 triples)</em></li>
        </ul>
      </li>
      <li>
        <code>?person dbo:birthPlace ?city.</code>
        <span class="next count">12,000,000</span>
        <ul>
          <li><em>(first 100 triples)</em></li>
        </ul>
      </li>
      <li>
        <code>?city foaf:name "Waterloo"@en.</code>
        <span class="next count">26</span>
        <ul>
          <li><em>(first 100 triples)</em></li>
        </ul>
      </li>
    </ol>
  </div>

  <div class="slide" id="tpf-pick-fragment">
    <h2>
      It starts with the smallest fragment,<br>
      because it is most selective.
    </h2>
    <ol class="query">
      <li>
        <code>?person rdf:type dbo:Artist.</code>
      </li>
      <li>
        <code>?person dbo:birthPlace ?city.</code>
      </li>
      <li>
        <strong><code>?city foaf:name "Waterloo"@en.</code></strong>
        <span class="count">26</span>
        <ul>
          <li class="next"><code>dbr:Waterloo,_Iowa foaf:name "Waterloo"@en.</code></li>
          <li class="next"><code>dbr:Waterloo,_London foaf:name "Waterloo"@en.</code></li>
          <li class="next"><code>dbr:Waterloo,_Ontario foaf:name "Waterloo"@en.</code></li>
          <li class="next">…</li>
        </ul>
      </li>
    </ol>
  </div>

  <div class="slide" id="tpf-recurse">
    <h2>
      This process continues recursively<br>
      until all options have been tested.
    </h2>
    <ol class="query">
      <li>
        <code>?person rdf:type dbo:Artist.</code>
      </li>
      <li>
        <code>?person dbo:birthPlace <strong>dbr:Waterloo,_Iowa</strong>.</code>
      <li>
        <strong><del><code>?city foaf:name "Waterloo"@en.</code></del></strong>
        <ul>
          <li><strong><code>dbr:Waterloo,_Iowa foaf:name "Waterloo"@en.</code></strong></li>
          <li><code>dbr:Waterloo,_London foaf:name "Waterloo"@en.</code></li>
          <li><code>dbr:Waterloo,_Ontario foaf:name "Waterloo"@en.</code></li>
          <li>…</li>
        </ul>
      </li>
    </ol>
  </div>

  <div class="slide" id="tpf-recurse-get-fragments">
    <h2>
      It gets the first page of all fragments<br>
      and inspects their metadata.
    </h2>
    <ol class="query">
      <li>
        <code>?person rdf:type dbo:Artist.</code>
        <span class="next count">96,000</span>
        <ul>
          <li><em>(first 100 triples)</em></li>
        </ul>
      </li>
      <li>
        <code>?person dbo:birthPlace dbr:Waterloo,_Iowa.</code>
        <span class="next count">45</span>
        <ul>
          <li><em>(first 100 triples)</em></li>
        </ul>
      </li>
    </ol>
  </div>

  <div class="slide" id="tpf-recurse-pick-fragment">
    <h2>
      It starts with the smallest fragment,<br>
      because it is most selective.
    </h2>
    <ol class="query">
      <li>
        <code>?person rdf:type dbo:Artist.</code>
        <span class="count">96,000</span>
      </li>
      <li>
        <strong><code>?person dbo:birthPlace dbr:Waterloo,_Iowa.</code></strong>
        <span class="count">45</span>
        <ul>
          <li><code>dbr:Allan_Carpenter dbo:birthPlace dbr:Waterloo,_Iowa.</code></li>
          <li><code>dbr:Adam_DeVine dbo:birthPlace dbr:Waterloo,_Iowa.</code></li>
          <li><code>dbr:Bonnie_Koloc dbo:birthPlace dbr:Waterloo,_Iowa.</code></li>
          <li>…</li>
        </ul>
      </li>
    </ol>
  </div>

  <div class="slide" id="tpf-recurse-final">
    <h2>
      This process continues recursively<br>
      until all options have been tested.
    </h2>
    <ol class="query">
      <li>
        <code><strong>dbr:Allan_Carpenter</strong> rdf:type dbo:Artist.</code>
      </li>
      <li>
        <strong><del><code>?person dbo:birthPlace dbr:Waterloo,_Iowa.</code></del></strong>
        <span class="count">26</span>
        <ul>
          <li><strong><code>dbr:Allan_Carpenter dbo:birthPlace dbr:Waterloo,_Iowa.</code></strong></li>
          <li><code>dbr:Adam_DeVine dbo:birthPlace dbr:Waterloo,_Iowa.</code></li>
          <li><code>dbr:Bonnie_Koloc dbo:birthPlace dbr:Waterloo,_Iowa.</code></li>
          <li>…</li>
        </ul>
      </li>
    </ol>
  </div>

  <div class="slide" id="tpf-first-solution">
    <h2>
      It gets the first page of the fragment,<br>
      which provides mappings for a solution.
    </h2>
    <ol class="query">
      <li>
        <code>dbr:Allan_Carpenter rdf:type dbo:Artist.</code>
        <span class="count">1</span>
        <ul>
          <li><code>dbr:Allan_Carpenter rdf:type dbo:Artist.</code></li>
        </ul>
      </li>
    </ol>
    <p class="next">We found a solution mapping.</p>
    <dl>
      <dt class="next"><var>?person</var></dt>
      <dd class="next"><a href="http://dbpedia.org/resource/Allan_Carpenter">dbr:Allan_Carpenter</a></dd>
      <dt class="next"><var>?city</var></dt>
      <dd class="next"><a href="http://dbpedia.org/resource/Waterloo,_Iowa">dbr:Waterloo,_Iowa</a></dd>
    </dl>
  </div>

  <div class="slide" id="tpf-no-solution">
    <h2>
      Some paths will result in empty fragments.<br>
      They do not lead to a consistent solution.
    </h2>
    <ol class="query">
      <li>
        <code>dbr:Adam_DeVine rdf:type dbo:Artist.</code>
        <span class="count">0</span>
      </li>
    </ol>
    <p class="next">No solution mapping.</p>
    <p class="next">
      <em>At least, according to DBpedia.<br>
          It turns out that <a href="http://www.imdb.com/name/nm2796745/">Adam DeVine</a> is actually an actor.</em>
    </p>
  </div>

  <div class="slide" id="tpf-query-client">
    <h2>
      Executing this query in the <a href="http://client.linkeddatafragments.org/#datasources=http%3A%2F%2Ffragments.dbpedia.org%2F2016-04%2Fen&query=SELECT%20%3Fperson%20%3Fcity%20WHERE%20%7B%0A%20%20%20%20%3Fperson%20rdf%3Atype%20dbpedia-owl%3AArtist.%0A%20%20%20%20%3Fperson%20dbpedia-owl%3AbirthPlace%20%3Fcity.%0A%20%20%20%20%3Fcity%20foaf%3Aname%20%22Waterloo%22%40en.%0A%7D">browser client</a><br>
      only takes a couple of seconds.
    </h2>
    <iframe class="query-client" src="../_shared/query-client/#datasources=http%3A%2F%2Ffragments.dbpedia.org%2F2016-04%2Fen&amp;query=SELECT%20%3Fperson%20%3Fcity%20WHERE%20%7B%0A%20%20%20%20%3Fperson%20rdf%3Atype%20dbpedia-owl%3AArtist.%0A%20%20%20%20%3Fperson%20dbpedia-owl%3AbirthPlace%20%3Fcity.%0A%20%20%20%20%3Fcity%20foaf%3Aname%20%22Waterloo%22%40en.%0A%7D"></iframe>
  </div>

  <div class="toc slide" id="evaluating-trade-offs">
    <h2>
      <a class="series" href="../">Web Fundamentals</a><br>
      <a class="module" href="#title">Linked Data Publishing</a>
    </h2>
    <ul>
      <li><a href="#life-cycle">Linked Data Life Cycle</a></li>
      <li><a href="#challenges">Semantic Web Challenges</a></li>
      <li class="current">
        <a href="#linked-data-fragments">Linked Data Fragments</a>
        <ul>
          <li><a href="#linked-data-fragments">Trade-offs for the Semantic Web</a></li>
          <li><a href="#querying-tpfs">Querying Triple Pattern Fragments</a></li>
          <li class="current"><a href="#evaluating-trade-offs">Evaluating the Trade-offs</a></li>
        </ul>
      </li>
    </ul>
    <p class="tweets"><a href="https://twitter.com/search?f=tweets&amp;q=%23WebDev2020">#WebDev2020</a></p>
  </div>

  <div class="slide" id="tpf-evaluation-benchmark">
    <h2>
      We evaluated Triple Pattern Fragments<br>
      for server cost and availability.
    </h2>
    <p>
      We ran the <a href="http://wifo5-03.informatik.uni-mannheim.de/bizer/berlinsparqlbenchmark/">Berlin SPARQL benchmark</a><br>
      on <a href="https://aws.amazon.com/ec2/">Amazon EC2 virtual machines</a>.
    </p>
    <ul>
      <li class="next">100 million triples</li>
      <li class="next">high query diversity</li>
      <li class="next"><code>BGP</code>, <code>UNION</code>, <code>FILTER</code>, …</li>
    </ul>
  </div>

  <div class="slide" id="tpf-evaluation-machines">
    <h2>
      We evaluated Triple Pattern Fragments<br>
      for server cost and availability.
    </h2>
    <p>
      We configured the Amazon machines<br>
      to generate large loads in a Web-like setting.
    </p>
    <ul>
      <li class="next">1 server (4 cores)</li>
      <li class="next">1 cache</li>
      <li class="next">1–244 simultaneous clients (1 core each)</li>
    </ul>
  </div>

  <div class="slide" id="tpf-evaluation-throughput">
    <h2 class="next">
      The query throughput is lower,<br>
      but resilient to high client numbers.
    </h2>
    <iframe class="image" src="images/tpf-throughput.svg"></iframe>
  </div>

  <div class="slide" id="tpf-evaluation-server-bandwidth">
    <h2 class="next">
      The server traffic is higher,<br>
      but individual requests are lighter.
    </h2>
    <iframe class="image" src="images/tpf-server-traffic.svg"></iframe>
  </div>

  <div class="slide" id="tpf-evaluation-cache-bandwidth">
    <h2 class="next">
      Caching is significantly more effective,<br>
      as clients reuse fragments for queries.
    </h2>
    <iframe class="image" src="images/tpf-cache-traffic.svg"></iframe>
  </div>

  <div class="slide" id="tpf-evaluation-server-cpu">
    <h2 class="next">
      The server requires much less CPU,<br>
      allowing higher availability at lower cost.
    </h2>
    <iframe class="image" src="images/tpf-server-cpu.svg"></iframe>
  </div>

  <div class="slide" id="tpf-evaluation-conclusion">
    <h2>
      The server <em>enables</em> clients to be intelligent,<br>
      so it can remain simple and lightweight.
    </h2>
    <iframe class="image" src="images/tpf-server-cpu.svg"></iframe>
  </div>

  <div class="slide" id="trade-offs">
    <h2>
      These experiments verify the possibility<br>
      (and necessity) of new types of solutions.
    </h2>
    <ul>
      <li class="next">
        Processing everything on the server is costly.<br>
        Processing everything on the client isn’t <em>Web</em>.
      </li>
      <li class="next">
        Solutions that divide the workload<br>
        can offer new perspectives,<br>
        if we accept the <em>trade-offs</em> they bring.
      </li>
      <li class="next opinion">
        Is it realistic to make all queries on the Web fast?
        <ul>
          <li>Maybe we should focus on obtaining first results soon.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="toc slide" id="recap">
    <h2>
      <a class="series" href="../">Web Fundamentals</a><br>
      <a class="module" href="#title">Linked Data Publishing</a>
    </h2>
    <ul>
      <li><a href="#life-cycle">Linked Data Life Cycle</a></li>
      <li><a href="#challenges">Semantic Web Challenges</a></li>
      <li><a href="#linked-data-fragments">Linked Data Fragments</a></li>
    </ul>
    <p class="tweets"><a href="https://twitter.com/search?f=tweets&amp;q=%23WebDev2020">#WebDev2020</a></p>
  </div>

  <div class="slide" id="sustainability">
    <h2 class="opinion">
      The Semantic Web should focus on making<br>
      <em>each</em> of the life cycle phases sustainable.
    </h2>
    <ul>
      <li class="next">
        Continuously improve Linked Data<br>
        through efficient iterations of the cycle.
      </li>
      <li class="next opinion">
        If we want to see intelligent agents,<br>
        we must stop building intelligent servers.
      </li>
      <li class="next">
        Another perspective on sustainability:<br>
        how can I <em>enable</em> others to act on my data<br>
        now and in the future?
      </li>
    </ul>
  </div>

  <footer>
    <p class="badge"><a href="https://github.com/RubenVerborgh/WebFundamentals">View on GitHub</a></p>
    <p class="license">
      <a rel="license" href="https://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" src="../_shared/images/cc-by-small.svg" /></a>
      Except where otherwise noted, the content of these slides is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
    </p>
  </footer>
  <script src="../_shared/scripts/shower.min.js"></script>
  <script src="../_shared/scripts/enhancements.js"></script>
  <script>ga=function(){ga.q.push(arguments)};ga.q=[['create','UA-6142365-12','auto'],['require','autotrack'],['send','pageview']];ga.l=1*new Date</script>
  <script async src="//www.google-analytics.com/analytics.js"></script>
  <script async src="../_shared/scripts/autotrack.js"></script>
</body>
</html>
